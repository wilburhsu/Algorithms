[toc]
# 1.分布式系统

## ==1.1 为什么要进行系统拆分==

为什么要进行系统拆分？如何进行系统拆分？拆分后不用 Dubbo 可以吗？

## ==1.2 分布式服务框架==

### 1.2.1 Dubbo

- 说一下 Dubbo 的工作原理？注册中心挂了可以继续通信吗？
- Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？
- Dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
- Dubbo 的 spi 思想是什么？
- 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？
- 分布式服务接口的幂等性如何设计（比如不能重复扣款）？
- 分布式服务接口请求的顺序性如何保证？
- 如何自己设计一个类似 Dubbo 的 RPC 框架？
- CAP 定理的 P 是什么？

### 1.2.2 Spring Cloud

1. 服务注册中心

2. 路由网关
3. 声明式服务调用、负载均衡

## ==1.3 分布式锁==

### 1.3.1 ZooKeeper应用场景

zookeeper 的几个简单使用场景如下：

- 分布式协调
- 分布式锁
- 元数据/配置信息管理
- HA高可用性

#### 分布式协调

这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上**对某个节点的值注册个监听器**，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。

![zookeeper-distributed-coordination](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE657a7b8262e8284bab6ab2189e31c4c5/9850)

#### 分布式锁

举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也**尝试去创建**那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。

![zookeeper-distributed-lock-demo](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE9e062ac31299ea9c7f2d354ebd09dc6c/9853)

#### 元数据/配置信息管理

zookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zookeeper 么？

![zookeeper-meta-data-manage](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE5040f162e52bbf6a0edf6fd0148656b6/9855)

#### HA高可用性

这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个**重要进程一般会做主备**两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。

![zookeeper-active-standby](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE38d002fa01c31cdf04af165be6f4798f/9857)

### 1.3.2 Redis分布式锁

官方叫做 `RedLock` 算法，是 Redis 官方支持的分布式锁算法。（Redisson）

这个分布式锁有 3 个重要的考量点：

- 互斥（只能有一个客户端获取锁）
- 不能死锁
- 容错（只要大部分 Redis 节点创建了这把锁就可以）

#### Redis最普通的分布式锁

第一个最普通的实现方式，就是在 Redis 里使用 `SET key value [EX seconds] [PX milliseconds] NX` 创建一个 key，这样就算加锁。其中：

- `NX`：表示只有 `key` 不存在的时候才会设置成功，如果此时 redis 中存在这个 `key`，那么设置失败，返回 `nil`。
- `EX seconds`：设置 `key` 的过期时间，精确到秒级。意思是 `seconds` 秒后锁自动释放，别人创建的时候如果发现已经有了就不能加锁了。
- `PX milliseconds`：同样是设置 `key` 的过期时间，精确到毫秒级。

比如执行以下命令：

```
SET resource_name my_random_value PX 30000 NX
```

释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除：

```
-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

为啥要用 `random_value` 随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 `lua` 脚本来释放锁。

但是这样是肯定不行的。因为如果是普通的 Redis 单实例，那就是单点故障。或者是 Redis 普通主从，那 Redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。

#### RedLock 算法

这个场景是假设有一个 Redis cluster，有 5 个 Redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
3. 尝试在**大多数节点**上建立一个锁，比如 5 个节点就要求是 3 个节点 `n / 2 + 1` ；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得**不断轮询去尝试获取锁**。

![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCEa132f7f41fc35953e12ac7f29f3028c3/9842)

### 1.3.3 ZooKeeper分布式锁

zk 分布式锁，其实可以做的比较简单，就是某个节点尝试创建临时 znode，此时创建成功了就获取了这个锁；这个时候别的客户端来创建锁会失败，只能**注册个监听器**监听这个锁。释放锁就是删除这个 znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新加锁。

```Java
/**
 * ZooKeeperSession
 */
public class ZooKeeperSession {

    private static CountDownLatch connectedSemaphore = new CountDownLatch(1);

    private ZooKeeper zookeeper;
    private CountDownLatch latch;

    public ZooKeeperSession() {
        try {
            this.zookeeper = new ZooKeeper("192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181", 50000, new ZooKeeperWatcher());
            try {
                connectedSemaphore.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }

            System.out.println("ZooKeeper session established......");
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * 获取分布式锁
     * 
     * @param productId
     */
    public Boolean acquireDistributedLock(Long productId) {
        String path = "/product-lock-" + productId;

        try {
            zookeeper.create(path, "".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);
            return true;
        } catch (Exception e) {
            while (true) {
                try {
                    // 相当于是给node注册一个监听器，去看看这个监听器是否存在
                    Stat stat = zk.exists(path, true);

                    if (stat != null) {
                        this.latch = new CountDownLatch(1);
                        this.latch.await(waitTime, TimeUnit.MILLISECONDS);
                        this.latch = null;
                    }
                    zookeeper.create(path, "".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);
                    return true;
                } catch (Exception ee) {
                    continue;
                }
            }

        }
        return true;
    }

    /**
     * 释放掉一个分布式锁
     * 
     * @param productId
     */
    public void releaseDistributedLock(Long productId) {
        String path = "/product-lock-" + productId;
        try {
            zookeeper.delete(path, -1);
            System.out.println("release the lock for product[id=" + productId + "]......");
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * 建立 zk session 的 watcher
     */
    private class ZooKeeperWatcher implements Watcher {

        public void process(WatchedEvent event) {
            System.out.println("Receive watched event: " + event.getState());

            if (KeeperState.SyncConnected == event.getState()) {
                connectedSemaphore.countDown();
            }

            if (this.latch != null) {
                this.latch.countDown();
            }
        }

    }

    /**
     * 封装单例的静态内部类
     */
    private static class Singleton {

        private static ZooKeeperSession instance;

        static {
            instance = new ZooKeeperSession();
        }

        public static ZooKeeperSession getInstance() {
            return instance;
        }

    }

    /**
     * 获取单例
     * 
     * @return
     */
    public static ZooKeeperSession getInstance() {
        return Singleton.getInstance();
    }

    /**
     * 初始化单例的便捷方法
     */
    public static void init() {
        getInstance();
    }

}
```

也可以采用另一种方式，创建临时顺序节点：

如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；后面的每个人都会去监听**排在自己前面**的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 ZooKeeper 给通知，一旦被通知了之后，就 ok 了，自己就获取到了锁，就可以执行代码了。

```Java
public class ZooKeeperDistributedLock implements Watcher {

    private ZooKeeper zk;
    private String locksRoot = "/locks";
    private String productId;
    private String waitNode;
    private String lockNode;
    private CountDownLatch latch;
    private CountDownLatch connectedLatch = new CountDownLatch(1);
    private int sessionTimeout = 30000;

    public ZooKeeperDistributedLock(String productId) {
        this.productId = productId;
        try {
            String address = "192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181";
            zk = new ZooKeeper(address, sessionTimeout, this);
            connectedLatch.await();
        } catch (IOException e) {
            throw new LockException(e);
        } catch (KeeperException e) {
            throw new LockException(e);
        } catch (InterruptedException e) {
            throw new LockException(e);
        }
    }

    public void process(WatchedEvent event) {
        if (event.getState() == KeeperState.SyncConnected) {
            connectedLatch.countDown();
            return;
        }

        if (this.latch != null) {
            this.latch.countDown();
        }
    }

    public void acquireDistributedLock() {
        try {
            if (this.tryLock()) {
                return;
            } else {
                waitForLock(waitNode, sessionTimeout);
            }
        } catch (KeeperException e) {
            throw new LockException(e);
        } catch (InterruptedException e) {
            throw new LockException(e);
        }
    }

    public boolean tryLock() {
        try {
 		    // 传入进去的locksRoot + “/” + productId
		    // 假设productId代表了一个商品id，比如说1
		    // locksRoot = locks
		    // /locks/10000000000，/locks/10000000001，/locks/10000000002
            lockNode = zk.create(locksRoot + "/" + productId, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
   
            // 看看刚创建的节点是不是最小的节点
	 	    // locks：10000000000，10000000001，10000000002
            List<String> locks = zk.getChildren(locksRoot, false);
            Collections.sort(locks);
	
            if(lockNode.equals(locksRoot+"/"+ locks.get(0))){
                //如果是最小的节点,则表示取得锁
                return true;
            }
	
            //如果不是最小的节点，找到比自己小1的节点
	  int previousLockIndex = -1;
            for(int i = 0; i < locks.size(); i++) {
		if(lockNode.equals(locksRoot + “/” + locks.get(i))) {
	         	    previousLockIndex = i - 1;
		    break;
		}
	   }
	   
	   this.waitNode = locks.get(previousLockIndex);
        } catch (KeeperException e) {
            throw new LockException(e);
        } catch (InterruptedException e) {
            throw new LockException(e);
        }
        return false;
    }

    private boolean waitForLock(String waitNode, long waitTime) throws InterruptedException, KeeperException {
        Stat stat = zk.exists(locksRoot + "/" + waitNode, true);
        if (stat != null) {
            this.latch = new CountDownLatch(1);
            this.latch.await(waitTime, TimeUnit.MILLISECONDS);
            this.latch = null;
        }
        return true;
    }

    public void unlock() {
        try {
            // 删除/locks/10000000000节点
            // 删除/locks/10000000001节点
            System.out.println("unlock " + lockNode);
            zk.delete(lockNode, -1);
            lockNode = null;
            zk.close();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (KeeperException e) {
            e.printStackTrace();
        }
    }

    public class LockException extends RuntimeException {
        private static final long serialVersionUID = 1L;

        public LockException(String e) {
            super(e);
        }

        public LockException(Exception e) {
            super(e);
        }
    }
}
```

### 1.3.4 redis 分布式锁和 zk 分布式锁的对比

- redis 分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。
- zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。

另外一点就是，如果是 Redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。

Redis 分布式锁大家没发现好麻烦吗？遍历上锁，计算时间等等......zk 的分布式锁语义清晰实现简单。

所以先不分析太多的东西，就说这两点，我个人实践认为 zk 的分布式锁比 Redis 的分布式锁牢靠、而且模型简单易用。

## ==1.4 分布式事务==

分布式事务了解吗？你们如何解决分布式事务问题的？TCC 如果出现网络连不通怎么办？XA 的一致性如何保证？

分布式事务框架Seata

## ==1.5 分布式会话==

集群部署时的分布式 Session 如何实现？

## ==1.6 流式处理框架（实时计算Flink）==

# 2. 高并发架构

## ==2.1 如何设计一个高并发系统==

秒杀系统设计

微博Feed流系统设计

## 2.2 消息队列

### 2.2.1 消息队列使用场景及优缺点

优点：消息队列的三个核心使用场景：解耦、异步、削峰

- 解耦：一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦，但是其实这个调用是不需要直接同步调用接口的，这里就可以考虑使用MQ进行系统解耦。通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，上游系统就跟其它下游系统彻底解耦了
- 异步：
- 削峰：典型的使用场景就是秒杀业务用于流量削峰场景

缺点：系统可用性降低，系统复杂度提高，一致性问题

### 2.2.2 消息队列的推拉模式

在rocketmq里，consumer被分为2类：MQPullConsumer和MQPushConsumer，其实本质都是拉模式（pull），即consumer轮询从broker拉取消息。
区别是：
push方式里，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。

pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。

### 2.2.3 消息队列的高可用

#### RabbitMQ的高可用性

RabbitMQ**基于主从**（非分布式）实现高可用性。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

1. 单机模式：Demo级别

2. 普通集群模式（无高可用性）（只同步queue元数据，不同步消息数据）

   - 普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。
   - **创建的 queue，只会放在一个 RabbitMQ 实例上**，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。
   - 消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
   
   缺点：
   
   - **MQ内部可能产生大量的数据传输。没做到所谓的分布式**，就是个普通集群。因为这种模式导致要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。
   - 可用性无保障，queue所在节点宕机，数据就丢了。如果开启了消息持久化，**让 RabbitMQ 落地存储消息的话**，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。

​		普通集群模式**主要是提高吞吐量的**，就是说让集群中多个节点来服务某个 queue 的读写操作。

3. 镜像集群模式（高可用性）（既同步queue元数据，也同步消息数据）

   - 在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据
   - 每次写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

   缺点：
   
   - 性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重
   - 不是分布式的，**没有扩展性可言**，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**

#### Kafka的高可用性

Kafka最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

Partition分区数和Broker数关系：

1. 如果**Partition数等于Broker数**， Kafka集群将比较均衡
2. 如果**Partition数小于Broker数**，某个Broker节点上不存在当前topic的分区，Broker节点可能被闲置，最终导致Kafka集群吞吐率下降
3. 如果**Partition数大于Broker数**，抛异常：java.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0...0]，建议将Partition数必须设置为Broker数的整数倍

HA机制：副本机制

1. Kafka 0.8 以后，提供了 HA 机制，就是 **replica（复制品） 副本机制**。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。
2. 所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。
3. 写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader原因如下：**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

副本机制是如何实现高可用的：

1. 如果某个 broker 宕机了，那个 broker上面的 partition 在其他机器上都有副本。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。
2. **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）
3. **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

#### ==RocketMQ的高可用性==



### 2.2.4 消息不被重复消费（消息消费的幂等性）

Kafka重复消费场景：

1. Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
2. 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。

需要结合业务来看，主要有如下思路：

- 比如拿个数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
- 比如是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如不是上面两个场景，那做的稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后消费者这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

### 2.2.5 消息的可靠性传输（如何处理消息丢失的问题）

#### RabbitMQ的可靠性处理

1. 生产者丢数据

   **开启RabbitMQ事务**（同步，消耗性能，吞吐量下降大，不推荐）

   - 生产者**发送数据之前**开启 RabbitMQ 事务 `channel.txSelect` ，然后发送消息；

   - 如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 `channel.txRollback` ，然后重试发送消息；

   - 如果收到了消息，那么可以提交事务 `channel.txCommit` 。

   **开启confirm模式**（异步，推荐）

   - 在生产者端设置开启 `confirm` 模式之后，每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会回传一个 `ack` 消息，告知你这个消息 ok 了。

   - 如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。

   - 你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

2. RabbitMQ丢数据

   **开启 RabbitMQ 的持久化**，消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，**可能导致少量数据丢失**，但是这个概率较小。

   设置持久化有**两个步骤**：

   - 创建 queue 的时候将其设置为持久化

   这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。

   - 消息设置为持久化

   发送消息的时候将消息的 `deliveryMode` 设置为 2，此时 RabbitMQ 就会将消息持久化到磁盘上去。

   **必须要同时设置这两个持久化才行**，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

   极端情况：哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

   所以，**持久化可以跟生产者那边的 `confirm` 机制配合起来**，只有**消息被持久化到磁盘之后，才会通知生产者 `ack`** 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack` ，你也是可以自己重发的。

3. 消费者丢数据（**关闭RabbitMQ自动ack**）

   消费者如果丢失了数据，主要是因为你消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，RabbitMQ 认为你都消费了，这数据就丢了。
   
   这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack` ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，就没有 `ack` 了。那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

#### Kafka的可靠性处理

1. 消费者丢失数据

   消费者唯一丢数据的情况：消费者消费到消息后，消费者那边**自动提交了 offset**，Kafka 认为消费者已经消费好了这个消息，但其实消费者才刚准备处理这个消息，还没处理，自己就挂了，此时这条消息就丢失了。

   解决方法： Kafka 会自动提交 offset，那么只要**关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

2. Kafka丢失数据

   Kakfa丢失数据场景：Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。如果此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，还没有同步的数据就丢失了。

   解决方法：一般是要求起码设置如下 4 个参数：

   - 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求**每个 partition 必须有至少 2 个副本**。
   - 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求**一个 leader 至少感知到有一个 follower 还跟自己保持联系**，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
   - 在 producer 端设置 `acks=all` ：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
   - 在 producer 端设置 `retries=MAX` （很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。

3. 生产者会不会丢失数据？

   如果按照上述的思路设置了 `acks=all` ，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

#### ==RocketMQ的可靠性处理==



### 2.2.6 消息的顺序性

消息顺序错乱的场景：

1. RabbitMQ

   一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。数据就出现了明显的错乱。

2. Kafka

   比如说我们建了一个 topic，有三个 partition。

   生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。

   消费者从 partition 中取出来数据的时候，也一定是有顺序的。

   到这里，顺序还是 ok 的，没有错乱。

   接着，我们在消费者里可能会搞**多个线程来并发处理消息**。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。

解决方案：

1. RabbitMQ

   - 拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；

   - 就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

2. Kafka

   - 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
   - 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

### 消息队列延时、过期失效、积压问题

如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？

具体场景的解决办法：

1. 大量消息在MQ 里积压了几个小时了还没解决

   临时紧急扩容，具体操作步骤和思路如下：

   - 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
   - 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
   - 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
   - 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
   - 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。

2.  MQ中的消息过期失效了

   消息队列设置过期时间之后，如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了，导致大量的数据直接丢失

   解决方法：

   **批量重导**。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。

3.  MQ都快写满了

   临时写程序，接入数据来消费，**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据。

### 如何设计一个消息队列

参照开源技术从如下几个角度进行考虑：

- 首先这个 mq 得**支持可伸缩性**，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
- 其次你得考虑一下这个 mq 的**数据要不要落地磁盘**吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。
- 其次你考虑一下你的 mq 的**可用性**啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
- 能不能支持**数据 0 丢失**啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

## ==2.3 搜索引擎（ElasticSearch）==



## 2.4 缓存

### 2.4.1 Redis线程模型

Redis 基于Reactor模式开发了自己的网路事件处理器，这个处理器被称为文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序（编译时自动选择系统中性能最高的I/O多路复用函数库）
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/2D15E716EF694B46B5CE5ED24C3AAEAB/11667)

客户端与 Redis 的一次通信过程：

![image](https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/FDA1084D00C34C1392074E780D4D76FD/9776)

1. 首先，Redis 服务端进程初始化的时候，会将 server socket 的 `AE_READABLE` 事件与连接应答处理器关联。

2. 客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给**连接应答处理器**。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。

3. 假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。

4. 如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok` ，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。

为什么 Redis 单线程模型也能效率这么高？

- 纯内存操作。
- 核心是基于非阻塞的 IO 多路复用机制。
- C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。
- 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。

**注意！** Redis 6.0 之后的版本抛弃了单线程模型这一设计，**原本使用单线程运行的 Redis 也开始选择性地使用多线程模型**。

前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。

**Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。** 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。

### 2.4.2 五个对象及底层数据结构

底层数据结构

| 对象所使用的底层数据结构 | OBJECT ENCODING 命令输出 |
| :--- | :--- |
| 整数 | int |
| embstr编码的简单动态字符串（SDS） | embstr |
| 简单动态字符串 | raw |
| 字典 | hashtable |
| 双端链表 | linkedlist |
| 压缩列表 | ziplist |
| 整数集合 | intset |
| 跳跃表和字典 | skiplist |

简单动态字符串（SDS）

- 常数时间复杂度获取字符串长度
- 杜绝缓冲区溢出：先扩展再拼接
- 减少修改时的内存分配次数
- 二进制安全
- 兼容部分C字符串函数

五种对象的底层实现

| 类型                  | 编码                | 备注                                                         |
| --------------------- | ------------------- | ------------------------------------------------------------ |
| 字符串（String）      | int，raw，embstr    | 普通的 set 和 get，做简单的 KV 缓存                          |
| 有序列表（List）      | ziplist，linkedlist | 通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类<br />通过 lrange 命令，读取某个闭区间内的元素<br />实现简单的消息队列 |
| 哈希对象（Hash）      | ziplist，hashtable  | 可存储结构化的数据，比如一个对象（无对象嵌套）               |
| 集合对象（ Set）      | intset，hashtable   | 无序集合，自动去重<br />基于 set 可以实现交集、并集、差集的操作 |
| 有序集合对象（ ZSet） | ziplist，skiplist   | 排序的 set，去重但可以排序                                   |


### 2.4.3 过期删除机制，淘汰机制

Redis 过期策略是：**定期删除+惰性删除**。

**定期删除**：Redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。

**惰性删除**：定期删除可能会导致很多过期 key 到了时间并没有被删除掉，这种情况下走惰性删除。即获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。

**内存淘汰机制**：如果定期删除漏掉了很多过期 key，然后也没及时去查，也就没走惰性删除，如果大量过期 key 堆积在内存里，有可能会导致 Redis 内存块耗尽，此时走内存淘汰机制

Redis 内存淘汰机制有以下几个：

- noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
- **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key（这个是**最常用**的）。
- allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
- volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key（这个一般不太合适）。
- volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key。
- volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除。

利用已有的 JDK 数据结构实现一个 Java 版的 LRU：

```Java
class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;

    /**
     * 传递进来最多能缓存多少数据
     *
     * @param cacheSize 缓存大小
     */
    public LRUCache(int cacheSize) {
        // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最早访问的放在尾部。
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

     /**
     * LinkedHashMap自带的判断是否删除最老的元素方法，默认返回false，即不删除老数据
     * 我们要做的就是重写这个方法，当满足一定条件时删除老数据
     * 钩子方法，通过put新增键值对的时候，若该方法返回true
     * 便移除该map中最老的键和值
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
        return size() > CACHE_SIZE;
    }
}
```

### 2.4.4 持久化

#### Redis 持久化的两种方式

- RDB：RDB 持久化机制，是对 Redis 中的数据执行**周期性**的持久化，
- AOF：AOF 机制对每条写入命令作为日志，以 `append-only` 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过**回放** AOF 日志中的写入指令来重新构建整个数据集。

如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会优先使用 **AOF** 来重新构建数据，因为 AOF 文件更新频率更高，**数据更加完整**。

只有在AOF持久化功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。

#### RDB 

RDB实现

- 通过SAVE和BGSAVE命令生成RDB文件
- SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕，服务器进程阻塞期间，不能处理任何命令请求。
- BGSAVE命令会派生出一个子进程，由子进程执行磁盘 IO 操作负责创建RDB文件，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。服务器进程（父进程）继续处理命令请求。可以通过设置save选项（设置一段时间内的修改次数），让服务器每隔一段时间自动执行一次BGSAVE命令
- RDB文件的载入是在服务器启动时自动执行，没有专门的载入命令，只要启动时检测到RDB文件存在，就会自动载入RDB文件。在载入RDB文件期间，服务器会一直处于阻塞状态直到载入工作完成

RDB优缺点

- RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式，**非常适合做冷备**，以预定好的备份策略来定期备份 Redis 中的数据。
- RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis **保持高性能**，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。
- 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。
- 如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟的数据。
- RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。

#### AOF 

AOF 实现

- AOF持久化功能的实现分为三个步骤：命令追加（append），文件写入，文件同步（sync）

- 服务器在执行完一个写命令后，以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾，之后再定期写入并同步到AOF文件
- appendfsync选项的不同值对AOF持久化功能的安全性以及Redis服务器的性能有很大的影响
- AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一致，但体积更小。
- 在执行BGREWRITEAOF命令时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有命令。当Redis服务器执行完一个写命令后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作

AOF 优缺点

- AOF 可以**更好的保护数据不丢失**，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 `fsync` 操作，最多丢失 1 秒钟的数据。
- AOF 日志文件以 `append-only` 模式写入，所以没有任何磁盘寻址的开销，**写入性能非常高**，而且文件不容易破损，即使文件尾部破损，也很容易修复。
- AOF 日志文件即使过大的时候，出现后台重写操作，也**不会影响客户端的读写**。
- AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常**适合做灾难性的误删除的紧急恢复**。比如某人不小心用 `flushall` 命令清空了所有数据，只要这个时候后台 `rewrite` 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 `flushall` 命令给删了，然后再将该 `AOF` 文件放回去，就可以通过恢复机制，自动恢复所有数据。
- 对于同一份数据来说，**AOF 日志文件通常比 RDB 数据快照文件更大**。
- AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 `fsync` 一次日志文件，当然，每秒一次 `fsync` ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）
- 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是**基于当时内存中的数据进行指令的重新构建**，这样健壮性会好很多。

4. RDB和AOF选择

   - 不要仅仅使用 RDB，因为那样会导致丢失很多数据；
   - 也不要仅仅使用 AOF，因为那样有两个问题：第一，通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；
   - Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

### 2.4.5 主从复制

主从架构可实现 Redis 高并发，一主多从，读写分离

Redis replication -> 主从架构 -> 读写分离 -> 水平扩容支撑读高并发

#### Redis同步功能实现原理

复制功能分为同步（sync）和命令传播（command propagate）两个操作。

1. 旧版主从复制（Redis 2.8版本以前）

   旧版复制缺陷：从服务器对主服务器的同步操作是通过向SYNC命令来完成，这个命令需要主服务器执行BGSAVE命令来生成RDB文件，然后将生成的RDB文件发送给从服务器，这个发送操作会耗费从服务器大量的网络资源，并对主服务器响应命令请求的时间产生影响。在载入接收到的RDB文件期间，从服务器是阻塞的。断线后重连是通过发送SYNC命令实现的，效率低下。

2. 新版主从复制（Redis 2.8版本以后）

   使用PSYNC命令代替了SYNC命令来执行复制时的同步操作。PSYNC命令具有完整重同步（`full resynchronization`）和部分重同步（`partial resynchronization`）两种模式

   完整重同步：

   - master 执行 bgsave ，在本地生成一份 rdb 快照文件。
   - master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)
   - master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。
   - 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。

   ```
   client-output-buffer-limit slave 256MB 64MB 60
   ```

   - slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时**基于旧的数据版本**对外提供服务。
   - 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。

   部分重同步：

   - 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。
   - master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。
   - master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。

采用了主从架构，那么建议必须**开启** master node 的[持久化](https://gitee.com/Doocs/advanced-java/blob/master/docs/high-concurrency/redis-persistence.md)，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。

#### 主从复制的核心原理

1. 当启动一个 slave node 的时候，它会发送一个 `PSYNC` 命令给 master node。

2. 如果这是 slave node 初次连接到 master node，那么会触发一次 `full resynchronization` 全量复制。
3. 此时 master 会启动一个后台线程，开始生成一份 `RDB` 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。
4.  `RDB` 文件生成完毕后， master 会将这个 `RDB` 发送给 slave，slave 会先**写入本地磁盘，然后再从本地磁盘加载到内存**中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。
5. slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。（部分重同步操作）

![image](https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/305EB887D1E5455796B9132F2D21187D/9780)

主从复制的断点续传（通过部分重同步实现）：

1. 部分重同步功能由三个部分构成：
   - 主服务器的复制偏移量（replication offset）和从服务器的复制偏移量
   - 主服务器的复制积压缓冲区（repliaction backlog）（由主服务器维护的默认1MB的先进先出队列）
   - 服务器的运行 ID（run ID）

2. master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 `resynchronization` 。

无磁盘化复制：

- master 在内存中直接创建 `RDB` ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 `repl-diskless-sync yes` 即可。

过期key处理：

- slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。

#### 主从复制的流程

通过向从服务器发送SLAVEOF命令，可以让一个从服务器去复制一个主服务器。

1. 设置主服务器的地址和端口：slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 `host` 和 `ip` ，保存完成后，从服务器返回OK，实际的复制工作在返回OK后开始执行

2. 建立套接字连接：slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接

3. 发送PING命令：连接建立后，slave node 发送 `ping` 命令给 master node。如果从服务器读取到PONG回复，表示网络连接正常

4. 身份验证：接收到PONG回复后，

   - 如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。
   - 如果没有设置 requirepass，则不需要身份验证。

   在需要进行身份验证的情况下，从服务器将发送一条AUTH命令给主服务器，命令参数为从服务器requirepass选项的值

5. 发送端口信息：在身份验证后，从服务器将执行REPLCONF命令，向主服务器发送从服务器的监听端口号

6. 同步：在这一步，从服务器向主服务器发送PSYNC命令，master node **第一次执行全量复制**，将所有数据发给 slave node

7. 命令传播：在后续，master node 每次接收到写命令后，先在内部写入数据，再将写命令异步发送给 slave node。

<img src="https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE402eefd8f9cc1db14d97b4d1e10b2b16/9786" alt="image" style="zoom: 67%;" />

心跳检查：

主从节点互相都会发送 heartbeat 信息。master 默认每隔 10秒 发送一次 heartbeat，slave node 每隔 1秒 发送一个 heartbeat。

命令为REPLCONF ACK。主要有三个作用：

1. 检测主从服务器的连接状态
2. 辅助实现min-salves选项
3. 检测命令丢失

### 2.4.6 哨兵（Sentinel）

哨兵是运行在特殊模式下的Redis服务器，使用了和普通模式不同的命令表

#### 哨兵原理

1. 启动并初始化Sentinel

   Sentinel会读入用户指定的配置文件，为每个要被监视的主服务器创建相应的实例结构，并创建连向主服务器的命令连接和订阅连接，其中命令连接用于向主服务器发送命令请求，订阅连接用于接收指定频道的消息

2. 获取主服务器和从服务器信息

   Sentinel通过向主服务器发送INFO命令来获得主服务器属下所有从服务器的地址信息，并为这些从服务器创建相应的实例结构，以及连向这些从服务器的命令连接和订阅连接。

   一般情况下，Sentinel以每十秒一次的频率向被监视的主服务器和从服务器发送INFO命令，当主服务器处于下线状态，或者Sentinel正在对主服务器进行故障转移操作时，Sentinel向从服务器发送INFO命令的频率会改为每秒一次。

3. 向主从服务器发送信息

   对于监视同一个主服务器和从服务器的多个Sentinel来说，它们会以每两秒一次的频率，向被监视服务器的`__sentinel__:hello`频道发送消息来向其他Sentinel宣告自己的存在，消息内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。

   每个哨兵也会去**监听**自己监控的每个 master+slaves 对应的 `__sentinel__:hello` channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。

   每个哨兵还会跟其他哨兵交换对 `master` 的监控配置，互相进行监控配置的同步。

4. 接收来自主从服务器的频道消息

   哨兵互相之间的发现，是通过 Redis 的 `pub/sub` 系统实现的，每个Sentinel也会从`__sentinel__:hello`频道接收其他Sentinel发来的信息，并根据这些信息为其他Sentinel创建相应的实例结构以及命令连接

   Sentinel只会与主服务器和从服务器创建命令连接和订阅连接，Sentinel与Sentinel之间只创建命令连接

5. 检测主观下线（sdown）状态

   Sentinel以每秒一次的频率向实例（包括主服务器、从服务器、其他Sentinel）发送PING命令，并根据实例对PING命令的回复来判断实例是否在线，当一个实例在指定的时长中连续向Sentinel发送无效回复时，Sentinel会将这个实例判断为主观下线

6. 检测客观下线（odown）状态

   当Sentinel将一个主服务器判断为主观下线时，它会向同样监视这个主服务器的其他Sentinel进行询问，看它们是否同意这个主服务器已经进入主观下线状态。

   当Sentinel收集到足够多（大于等于设置的quorum 数量）的主观下线投票之后，它会将主服务器判断为客观下线，并发起一次针对主服务器的故障转移操作

7. 选举领头Sentinel

   <img src="https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCEd10d985e35ad93752d500720bd73a01c/9789" alt="image" style="zoom:50%;" />

8. 故障转移

   在选举出领头Sentinel之后，领头Sentinel将对已下线的主服务器执行故障转移操作，包含以下三个步骤：

   1）在已下线的主服务器属下的从服务器里面，挑选出一个从服务器，并将其转换为主服务器

   2）让已下线主服务器属下的所有从服务器改为复制新的主服务器

   3）将已下线主服务器设置为新的主服务器的从服务器，当这个旧的主服务器重新上线时，它就会成为新的主服务器的从服务器

#### 哨兵的核心知识

- 哨兵至少需要 3 个（>2，不能等于）实例，来保证自己的健壮性。

- 哨兵 + Redis 主从的部署架构，**不能保证数据零丢失**，只能保证 Redis 集群的高可用性。

- 对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。

  哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，quorum = 1。

  ```
  +----+         +----+
  | M1 |---------| R1 |
  | S1 |         | S2 |
  +----+         +----+
  ```

  配置 `quorum=1` ，如果 master 宕机， s1 和 s2 中只要有 1 个哨兵认为 master 宕机了，就可以进行切换，同时 s1 和 s2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 majority，也就是大多数哨兵都是运行的。

  ```
  2 个哨兵，majority=2
  3 个哨兵，majority=2
  4 个哨兵，majority=2
  5 个哨兵，majority=3
  ...
  ```

  如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。

  经典的 3 节点哨兵集群是这样的：

  ```
         +----+
         | M1 |
         | S1 |
         +----+
            |
  +----+    |    +----+
  | R2 |----+----| R3 |
  | S2 |         | S3 |
  +----+         +----+
  ```

  配置 `quorum=2` ，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个，S2 和 S3 可以一致认为 master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。

#### 哨兵主备切换的数据丢失问题

1. 数据丢失的两种情况

   - 异步复制导致的数据丢失

   因为 master->slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了。

   - 脑裂导致的数据丢失

   脑裂，也就是说，某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**。

   此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。

2. 数据丢失问题的解决方案

   进行如下配置：

   ```
   min-slaves-to-write 1
   min-slaves-max-lag 10
   ```

   表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。

   - 减少异步复制数据的丢失

   有了 `min-slaves-max-lag` 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。

   - 减少脑裂的数据丢失

   如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。

#### 选举算法和故障转移

1. slave->master 选举算法

   如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：

   - 跟 master 断开连接的时长
   - slave 优先级
   - 复制 offset
   - run id

   如果一个 slave 跟 master 断开连接的时间已经超过了 `down-after-milliseconds` 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。

   ```
   (down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state
   ```

   接下来会对 slave 进行排序：

   - 按照 slave 优先级进行排序，slave priority 越低，优先级就越高。
   - 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。
   - 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。

2. quorum 和 majority

   每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。

   如果 quorum < majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。

   但是如果 quorum >= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。

3. configuration epoch

   哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。

   执行切换的那个哨兵，会从要切换到的新 master（salve->master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。

   如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。

4. configuration 传播

   哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 `pub/sub` 消息机制。

   这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。

### 2.4.7 Redis集群

Redis cluster，主要是针对**海量数据+高并发+高可用**的场景。Redis cluster 支撑 N 个 Redis master node，每个 master node 都可以挂载多个 slave node。这样整个 Redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。

####  Redis cluster 介绍

- 自动将数据进行分片，每个 master 上放一部分数据
- 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的

在 Redis cluster 架构下，每个 Redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。

16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议， `gossip` 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。

1. 节点

   节点通过握手来讲其他节点添加到自己所处的集群当中，连接各个节点的工作可以使用CLUSTER MEET命令来完成

2. 槽指派

   集群中的16384个槽可以分别指派给集群中的各个节点（使用CLUSTER ADDSLOTS命令），每个节点都会记录哪些槽指派给了自己，而哪些槽又被指派给了其他节点（存储在clusterState结构中）。集群中的每个节点可以处理0个或者最多16384个槽。

   当数据库中16384个槽都有节点在处理时，集群处于上线状态（ok）；反之，如果有任何一个槽没有得到处理，那么集群处于下线状态（fail）

3. 在集群中执行命令

   节点在接到一个命令请求时，会先检查这个命令请求要处理的键所在的槽是否由自己负责。如果不是的话，节点将向客户端返回一个MOVED错误，MOVED错误携带的信息可以指引客户端转向至正在负责相关槽的节点

4. 重新分片

   对Redis集群的重新分片工作是由redis-trib（集群管理软件）负责执行的，重新分片的关键是将属于某个槽的所有健值对从一个节点转移至另一个节点

5. ASK错误

   如果节点A正在迁移i至节点B，那么节点A没能在自己的数据库中找到命令指定的数据库键时，节点A会向客户端返回一个ASK错误，指引客户端到节点B继续查找指定的数据库键

   MOVED错误表示槽的负责全已经从一个节点转移到了另一个节点，而ASK错误只是两个节点在迁移槽的过程中使用的一种临时措施

6. 复制与故障转移

   集群里的从节点用于复制主节点，并在主节点下线时，代替主节点继续处理命令请求

7. 消息

   集群中的节点通过发送和接收消息来进行通信，常见的消息包括MEET、PING、PONG、PUBLISH、FAIL五种

#### 节点内部的通信机制

1. 基本通信原理

   集群元数据的维护有两种方式：集中式、Gossip 协议。Redis cluster 节点间采用 gossip 协议进行通信。

   **集中式**是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 `storm` 。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。

   **集中式**的**好处**在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；**不好**在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。

   ![](https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE0215bde7018f93e8691b568c50eba283/9793)

   Redis 维护集群元数据采用另一个方式， `gossip` 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。

   <img src="https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCEcb956ab37327bd60b344c3c2cd584fd3/9797" style="zoom: 67%;" />

   gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

   - 10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 `ping` 消息，同时其它几个节点接收到 `ping` 之后返回 `pong` 。
   - 交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。

2. Gossip协议

   gossip 协议包含多种消息，包含 `ping` , `pong` , `meet` , `fail` 等等。

   - meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。

   ```
   Redis-trib.rb add-node
   ```

   其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。

   - ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。
   - pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。
   - fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点，某个节点宕机。

3. ping消息深入

   ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。

   每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 `cluster_node_timeout / 2` ，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 `cluster_node_timeout` 可以调节，如果调得比较大，那么会降低 ping 的频率。

   每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 `3` 个其它节点的信息，最多包含 `总节点数减 2` 个其它节点的信息。

#### 分布式寻址算法

1. hash算法（大量缓存重建）

   来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致**大部分的请求过来，全部无法拿到有效的缓存**，导致大量的流量涌入数据库。

2. 一致性哈希算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）

   一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。

   来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环**顺时针“行走”**，遇到的第一个 master 节点就是 key 所在位置。

   在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。

   然而，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成**缓存热点**的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。

   <img src="https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE69dd61e8e7a54f6a9b55336625f2293e/9804" style="zoom: 67%;" />

3. Redis cluster 的 hash slot 算法

   Redis cluster 有固定的 `16384` 个 hash slot，对每个 `key` 计算 `CRC16` 值，然后对 `16384` 取模，可以获取 key 对应的 hash slot。
   
   Redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 `hash tag` 来实现。
   
   任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。
   
   ![](https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE2705b3d20c0af4237f3c87c2f9049c2a/9807)

#### Redis cluster 的高可用与主备切换原理

对于槽位的转移和分派，Redis集群是不会自动进行的，而是需要人工配置的。所以Redis集群的高可用是依赖于节点的主从复制与主从间的自动故障转移。

1. 判断节点宕机

   如果一个节点认为另外一个节点宕机，那么就是 `pfail` ，**主观宕机**。如果多个节点都认为另外一个节点宕机了，那么就是 `fail` ，**客观宕机**，跟哨兵的原理几乎一样，sdown，odown。

   在 `cluster-node-timeout` 内，某个节点一直没有返回 `pong` ，那么就被认为 `pfail` 。

   如果一个节点认为某个节点 `pfail` 了，那么会在 `gossip ping` 消息中， `ping` 给其他节点，如果**超过半数**的节点都认为 `pfail` 了，那么就会变成 `fail` 。

2. 从节点过滤

   对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。

   检查每个 slave node 与 master node 断开连接的时间，如果超过了 `cluster-node-timeout * cluster-slave-validity-factor` ，那么就**没有资格**切换成 `master` 。

3. 从节点选举

   每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。

   所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node `（N/2 + 1）` 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

   从节点执行主备切换，从节点切换为主节点。

4. 与哨兵比较

   整个流程跟哨兵相比，非常类似，所以说，Redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。

### 2.4.8 事务

1. 事务提供了一种将多个命令打包，然后一次性有序地执行的机制。MULTI命令标志着事务的开始，该命令可以将客户端从非事务状态切换至事务状态。
2. 多个命令会被入队到事务队列中，然后按照先进先出（FIFO）的顺序执行。当一个处于事务状态的客户端向服务器发送EXEC命令时，这个EXEC命令将立即被服务器执行。服务器会遍历这个客户端的事务队列，执行队列中保存的所有命令，最后将执行命令所得的结果全部返回给客户端
3. 事务在执行过程中不会被中断，当事务队列中的所有命令都被执行完毕之后，事务才会结束
4. 带有WATCH命令（是一个乐观锁）的事务会将客户端和被监视的键在数据库的watched_keys字典中进行关联，当键被修改时，程序会将所有监视被修改键的客户端的REDIS_DIRTY_CAS标志打开
5. 只有在客户端的REDIS_DIRTY_CAS标志未被打开时，服务器才会执行客户端提交的事务，否则的话，服务器将拒绝执行客户端提交的事务
6. Redis的事务总是具有ACID中的原子性、一致性和隔离性，当服务器运行在AOF持久化模式下，并且appendfsync的选项的值为always时，事务也具有耐久性

### 2.4.9 缓存并发竞争

- **解释：**

  **多客户端同时并发写**一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。顺序我们无法控制。

- 解决方案：

  Redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例（抢到锁）在操作某个 key，别人都不允许读和写。同时，写入时，比较当前数据的时间戳和缓存中数据的时间戳。

  ![](https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE852e650cb507a06ed504b9c77da76616/9811)

  要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。

  每次要**写之前，先判断**一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。

### 2.4.10 缓存雪崩、穿透、击穿

1. 缓存雪崩
   - 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。
   - 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死
   - 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

2. 缓存穿透

   - 在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。

   - 每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 `set -999 UNKNOWN` 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。
   - 布隆过滤器：利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

3. 缓存击穿
   - 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。
   - 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。
   - 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前**主动地重新构建缓存或者延后缓存的过期时间**，以保证所有的请求能一直访问到对应的缓存。

### 2.4.11 数据库和缓存双写一致性

[分布式之数据库和缓存双写一致性方案解析](https://www.cnblogs.com/rjzheng/p/9041659.html)

[如何保证缓存与数据库的双写一致性？](https://gitee.com/Doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md)

三种缓存更新策略：

- 先更新数据库，再更新缓存
- 先删除缓存，再更新数据库
- 先更新数据库，再删除缓存

1. 先更新数据库，再更新缓存（普遍反对的方案）

   **原因一（线程安全角度）**

   同时有请求A和请求B进行更新操作，那么会出现
   （1）线程A更新了数据库
   （2）线程B更新了数据库
   （3）线程B更新了缓存
   （4）线程A更新了缓存
   这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据

   **原因二（业务场景角度）**

   有如下两点：
   （1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。
   （2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

2. 先删除缓存，再更新数据库（适用于并发度不高的场景）

   该方案会导致不一致的原因是，同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

   （1）请求A进行写操作，删除缓存

   （2）请求B查询发现缓存不存在

   （3）请求B去数据库查询得到旧值

   （4）请求B将旧值写入缓存

   （5）请求A将新值写入数据库

   上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

   **解决的方法是采用延时双删策略**，伪代码如下

   ```java
   public void write(String key,Object data){
   	  redis.delKey(key);
   	  db.updateData(data);
   	  Thread.sleep(1000);
   	  redis.delKey(key);
   }
   ```

   转化为中文描述就是

   （1）先淘汰缓存

   （2）再写数据库（这两步和原来一样）

   （3）休眠1秒，再次淘汰缓存

   这么做，可以将1秒内所造成的缓存脏数据，再次删除。

   **那么，这个1秒怎么确定的，具体该休眠多久呢？**

   针对上面的情形，需要自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

   数据库采用读写分离架构的解决方案参见[分布式之数据库和缓存双写一致性方案解析](https://www.cnblogs.com/rjzheng/p/9041659.html)

3. 先更新数据库，再删除缓存

   最经典的缓存+数据库读写的模式，Cache Aside Pattern。

   - **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后放到缓存中，同时返回响应。
   - **命中**：应用程序从cache中取数据，取到后返回。
   - **更新**：先把数据存到数据库中，成功后，再让缓存失效（删除缓存）。

   **为什么是删除缓存，而不是更新缓存？**

   1. 在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

   2. 更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**

      举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有**大量的冷数据**。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**

      其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。

   该策略出现数据库和缓存不一致的两种解决方法：

   1. 维护一个内存队列的方式，做异步串行化。（适用于需要强一致性的场景）参见[如何保证缓存与数据库的双写一致性？](https://gitee.com/Doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md)
   2. 借助消息队列订阅binlog。参见[分布式之数据库和缓存双写一致性方案解析](https://www.cnblogs.com/rjzheng/p/9041659.html)

## 2.5 分库分表及读写分离

### 2.5.1 分库分表及常用中间件

#### 分表

比如你单表都几千万数据了，你确定你能扛住么？绝对不行，**单表数据量太大**，会极大影响你的 sql **执行的性能**，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。

分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。

#### 分库

分库是啥意思？一个库，一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。

#### 分库分表中间件

比较常见的包括：

- Cobar
- TDDL
- Atlas
- Sharding-jdbc
- Mycat

1. Cobar

   阿里 b2b 团队开发和开源的，属于 proxy 层方案，就是介于应用服务器和数据库服务器之间。应用程序通过 JDBC 驱动访问 Cobar 集群，Cobar 根据 SQL 和分库规则对 SQL 做分解，然后分发到 MySQL 集群不同的数据库实例上执行。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。

2. TDDL

   淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。

3. Atlas

   360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。

4. Sharding-jdbc

   当当开源的，属于 client 层方案，是[ `ShardingSphere` ](https://shardingsphere.apache.org/)的 client 层方案，[ `ShardingSphere` ](https://shardingsphere.apache.org/)还提供 proxy 层的方案 Sharding-Proxy。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1` 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。

5. Mycat

   基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。

6. 总结

   综上，现在其实建议考量的，就是 Sharding-jdbc（client 层方案） 和 Mycat（proxy 层方案），这两个都可以去考虑使用。

   Sharding-jdbc 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要**耦合** Sharding-jdbc 的依赖；

   Mycat 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了。

   通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。

#### 垂直拆分及水平拆分

**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。

![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCEd5d2c0cfc1daf139faea761b210f3854/9816)

**垂直拆分**的意思，就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。比较常见的是把一个大表拆开，订单表、订单支付表、订单商品表。

![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE6d90425d61a0d5cf13f82047039f2ba8/9823)

还有**表层面的拆分**，就是分表，将一个表变成 N 个表，就是**让每个表的数据量控制在一定范围内**，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。

无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，**中间件可以根据你指定的某个字段值**，比如说 userid，**自动路由到对应的库上去，然后再自动路由到对应的表里去**。

一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。

而且这儿还有两种**分库分表的方式**：

- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。
- 或者是按照某个字段 hash 一下均匀分散，这个较为常用。

range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。

hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。

### 2.5.2 分库分表的动态切换

#### 停机迁移方案

凌晨 12 点开始运维，网站或者 app 挂个公告，说 0 点到早上 6 点进行运维，无法访问。

接着到 0 点停机，系统停掉，没有流量写入了，此时老的单库单表数据库静止了。然后你之前得写好一个**导数的一次性工具**，此时直接跑起来，然后将单库单表的数据哗哗哗读出来，写到分库分表里面去。

导数完了之后，就 ok 了，修改系统的数据库连接配置啥的，包括可能代码和 SQL 也许有修改，那你就用最新的代码，然后直接启动连到新的分库分表上去。最后验证。

![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE4a8a2aeb43570054d574344dc983c220/9827)

#### 双写迁移方案

这个是我们常用的一种迁移方案，比较靠谱一些，不用停机，不用看北京凌晨 4 点的风景。

简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**，这就是所谓的**双写**，同时写俩库，老库和新库。

然后**系统部署**之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。

导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

接着当数据完全一致了，就 ok 了，基于仅仅使用分库分表的最新代码，重新部署一次，不就仅仅基于分库分表在操作了么，还没有几个小时的停机时间，很稳。所以现在基本玩儿数据迁移之类的，都是这么干的。

![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE3b63f2d999d43c2556dc83de1c46bafd/9829)

### 2.5.3 动态扩容缩容

对于分库分表来说，主要是面对以下问题：

- 选择一个数据库中间件，调研、学习、测试；
- 设计你的分库分表的一个方案，你要分成多少个库，每个库分成多少个表，比如 3 个库，每个库 4 个表；
- 基于选择好的数据库中间件，以及在测试环境建立好的分库分表的环境，然后测试一下能否正常进行分库分表的读写；
- 完成单库单表到分库分表的**迁移**，双写方案；
- 线上系统开始基于分库分表对外提供服务；
- 扩容了，扩容成 6 个库，每个库需要 12 个表，你怎么来增加更多库和表呢？

这个是你必须面对的一个事儿，就是你已经弄好分库分表方案了，然后一堆库和表都建好了，基于分库分表中间件的代码开发啥的都好了，测试都 ok 了，数据能均匀分布到各个库和各个表里去，而且接着你还通过双写的方案咔嚓一下上了系统，已经直接基于分库分表方案在搞了。

那么现在问题来了，你现在这些库和表又支撑不住了，要继续扩容咋办？这个可能就是说你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。

这都是玩儿分库分表线上必须经历的事儿。

#### 停机扩容（不推荐）

这个方案就跟停机迁移一样，步骤几乎一致，唯一的一点就是那个导数的工具，是把现有库表的数据抽出来慢慢倒入到新的库和表里去。但是最好别这么玩儿，有点不太靠谱，因为既然**分库分表**就说明数据量实在是太大了，可能多达几亿条，甚至几十亿，你这么玩儿，可能会出问题。

从单库单表迁移到分库分表的时候，数据量并不是很大，单表最大也就两三千万。那么你写个工具，多弄几台机器并行跑，1小时数据就导完了。这没有问题。

如果 3 个库 + 12 个表，跑了一段时间了，数据量都 1~2 亿了。光是导 2 亿数据，都要导个几个小时，6 点，刚刚导完数据，还要搞后续的修改配置，重启系统，测试验证，10 点才可以搞完。所以不能这么搞。

#### 优化后的方案

一开始上来就是 32 个库，每个库 32 个表，那么总共是 1024 张表。

我可以告诉各位同学，这个分法，第一，基本上国内的互联网肯定都是够用了，第二，无论是并发支撑还是数据量支撑都没问题。

每个库正常承载的写入并发量是 1000，那么 32 个库就可以承载 32 * 1000 = 32000 的写并发，如果每个库承载 1500 的写并发，32 * 1500 = 48000 的写并发，接近 5 万每秒的写入并发，前面再加一个MQ，削峰，每秒写入 MQ 8 万条数据，每秒消费 5 万条数据。

有些除非是国内排名非常靠前的这些公司，他们的最核心的系统的数据库，可能会出现几百台数据库的这么一个规模，128 个库，256 个库，512 个库。

1024 张表，假设每个表放 500 万数据，在 MySQL 里可以放 50 亿条数据。

每秒 5 万的写并发，总共 50 亿条数据，对于国内大部分的互联网公司来说，其实一般来说都够了。

谈分库分表的扩容，**第一次分库分表，就一次性给他分个够**，32 个库，1024 张表，可能对大部分的中小型互联网公司来说，已经可以支撑好几年了。

一个实践是利用 `32 * 32` 来分库分表，即分为 32 个库，每个库里一个表分为 32 张表。一共就是 1024 张表。根据某个 id 先根据 32 取模路由到库，再根据 32 取模路由到库里的表。

| orderId | id % 32 (库) | id / 32 % 32 (表) |
| ------- | ------------ | ----------------- |
| 259     | 3            | 8                 |
| 1189    | 5            | 5                 |
| 352     | 0            | 11                |
| 4593    | 17           | 15                |

刚开始的时候，这个库可能就是逻辑库，建在一个数据库上的，就是一个 MySQL 服务器可能建了 n 个库，比如 32 个库。后面如果要拆分，就是不断在库和 MySQL 服务器之间做迁移就可以了。然后系统配合改一下配置即可。

比如说最多可以扩展到 32 个数据库服务器，每个数据库服务器是一个库。如果还是不够？最多可以扩展到 1024 个数据库服务器，每个数据库服务器上面一个库一个表。因为最多是 1024 个表。

这么搞，是不用自己写代码做数据迁移的，都交给 DBA 来搞好了，但是 DBA 确实是需要做一些库表迁移的工作，但是总比你自己写代码，然后抽数据导数据来的效率高得多吧。

哪怕是要减少库的数量，也很简单，其实说白了就是按倍数缩容就可以了，然后修改一下路由规则。

这里对步骤做一个总结：

1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。
2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
3. 扩容的时候，申请增加更多的数据库服务器，装好 MySQL，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

### 2.5.4 分库分表后的主键处理

分库分表之后你必然要面对的一个问题，就是 id 咋生成？因为要是分成多个表之后，每个表都是从 1 开始累加，那肯定不对啊，需要一个**全局唯一**的 id 来支持。所以这都是你实际生产环境中必须考虑的问题。

#### 基于数据库的实现方案

1. 数据库自增 id

   这个就是说你的系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。

   这个方案的好处就是方便简单，谁都会用；**缺点就是单库生成**自增 id，要是高并发的话，就会有瓶颈的；如果你硬是要改进一下，那么就专门开一个服务出来，这个服务每次就拿到当前 id 最大值，然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值；但是**无论如何都是基于单个数据库**。

   **适合的场景**：你分库分表就俩原因，要不就是单库并发太高，要不就是单库数据量太大；除非是你**并发不高，但是数据量太大**导致的分库分表扩容，你可以用这个方案，因为可能每秒最高并发最多就几百，那么就走单独的一个库和表生成自增主键即可。

2. 设置数据库 sequence 或者表自增字段步长

   可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。

   比如说，现在有 8 个服务节点，每个服务节点使用一个 sequence 功能来产生 ID，每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。

   ![database-id-sequence-step](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCE941fac8bc7622254ea890eedc02d87cf/9833)

   **适合的场景**：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。

#### UUID

好处就是本地生成，不要基于数据库来了；不好之处就是，UUID 太长了、占用空间大，**作为主键性能太差**了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。

适合的场景：如果你是要随机生成个什么文件名、编号之类的，你可以用 UUID，但是作为主键是不能用 UUID 的。

```
UUID.randomUUID().toString().replace("-", "") -> sfsdf23423rr234sfdaf
```

#### 获取系统当前时间

这个就是获取当前时间即可，但是问题是，**并发很高的时候**，比如一秒并发几千，**会有重复的情况**，这个是肯定不合适的。基本就不用考虑了。

适合的场景：一般如果用这个方案，是将当前时间跟很多其他的业务字段拼接起来，作为一个 id，如果业务上你觉得可以接受，那么也是可以的。你可以将别的业务字段值跟当前时间拼接起来，组成一个全局唯一的编号。

#### snowflake 算法

snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bits 作为毫秒数，用 10 bits 作为工作机器 id，12 bits 作为序列号。

- 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
- 41 bits：表示的是时间戳，单位是毫秒。41 bits 可以表示的数字多达 `2^41 - 1` ，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
- 10 bits：记录工作机器 id，代表的是这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。但是 10 bits 里 5 个 bits 代表机房 id，5 个 bits 代表机器 id。意思就是最多代表 `2^5` 个机房（32 个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
- 12 bits：这个是用来记录同一个毫秒内产生的不同 id，12 bits 可以代表的最大正整数是 `2^12 - 1 = 4096` ，也就是说可以用这个 12 bits 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。

```
0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000
```

```Java
public class IdWorker {

    private long workerId;
    private long datacenterId;
    private long sequence;

    public IdWorker(long workerId, long datacenterId, long sequence) {
        // sanity check for workerId
        // 这儿不就检查了一下，要求就是你传递进来的机房id和机器id不能超过32，不能小于0
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(
                    String.format("worker Id can't be greater than %d or less than 0", maxWorkerId));
        }
        if (datacenterId > maxDatacenterId || datacenterId < 0) {
            throw new IllegalArgumentException(
                    String.format("datacenter Id can't be greater than %d or less than 0", maxDatacenterId));
        }
        System.out.printf(
                "worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d",
                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);

        this.workerId = workerId;
        this.datacenterId = datacenterId;
        this.sequence = sequence;
    }

    private long twepoch = 1288834974657L;

    private long workerIdBits = 5L;
    private long datacenterIdBits = 5L;

    // 这个是二进制运算，就是 5 bit最多只能有31个数字，也就是说机器id最多只能是32以内
    private long maxWorkerId = -1L ^ (-1L << workerIdBits);

    // 这个是一个意思，就是 5 bit最多只能有31个数字，机房id最多只能是32以内
    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);
    private long sequenceBits = 12L;

    private long workerIdShift = sequenceBits;
    private long datacenterIdShift = sequenceBits + workerIdBits;
    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;
    private long sequenceMask = -1L ^ (-1L << sequenceBits);

    private long lastTimestamp = -1L;

    public long getWorkerId() {
        return workerId;
    }

    public long getDatacenterId() {
        return datacenterId;
    }

    public long getTimestamp() {
        return System.currentTimeMillis();
    }

    public synchronized long nextId() {
        // 这儿就是获取当前时间戳，单位是毫秒
        long timestamp = timeGen();

        if (timestamp < lastTimestamp) {
            System.err.printf("clock is moving backwards.  Rejecting requests until %d.", lastTimestamp);
            throw new RuntimeException(String.format(
                    "Clock moved backwards.  Refusing to generate id for %d milliseconds", lastTimestamp - timestamp));
        }

        if (lastTimestamp == timestamp) {
            // 这个意思是说一个毫秒内最多只能有4096个数字
            // 无论你传递多少进来，这个位运算保证始终就是在4096这个范围内，避免你自己传递个sequence超过了4096这个范围
            sequence = (sequence + 1) & sequenceMask;
            if (sequence == 0) {
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            sequence = 0;
        }

        // 这儿记录一下最近一次生成id的时间戳，单位是毫秒
        lastTimestamp = timestamp;

        // 这儿就是将时间戳左移，放到 41 bit那儿；
        // 将机房 id左移放到 5 bit那儿；
        // 将机器id左移放到5 bit那儿；将序号放最后12 bit；
        // 最后拼接起来成一个 64 bit的二进制数字，转换成 10 进制就是个 long 型
        return ((timestamp - twepoch) << timestampLeftShift) | (datacenterId << datacenterIdShift)
                | (workerId << workerIdShift) | sequence;
    }

    private long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }

    private long timeGen() {
        return System.currentTimeMillis();
    }

    // ---------------测试---------------
    public static void main(String[] args) {
        IdWorker worker = new IdWorker(1, 1, 1);
        for (int i = 0; i < 30; i++) {
            System.out.println(worker.nextId());
        }
    }

}
```

怎么说呢，大概这个意思吧，就是说 41 bit 是当前毫秒单位的一个时间戳，就这意思；然后 5 bit 是你传递进来的一个**机房** id（但是最大只能是 32 以内），另外 5 bit 是你传递进来的**机器** id（但是最大只能是 32 以内），剩下的那个 12 bit序列号，就是如果跟你上次生成 id 的时间还在一个毫秒内，那么会把顺序给你累加，最多在 4096 个序号以内。

所以你自己利用这个工具类，自己搞一个服务，然后对每个机房的每个机器都初始化这么一个东西，刚开始这个机房的这个机器的序号就是 0。然后每次接收到一个请求，说这个机房的这个机器要生成一个 id，你就找到对应的 Worker 生成。

利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。

这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。

### 2.5.5 读写分离

1. MySQL 读写分离的实现

   其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

2. MySQL 主从复制原理

   主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。

   ![](http://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/WEBRESOURCEf08d784a6646fa3378b31cacc6b1d3d3/9838)

3. MySQL 主从同步的延时问题

   以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。

   是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。

   我们通过 MySQL 命令：

   ```
   show status
   ```

   查看 `Seconds_Behind_Master` ，可以看到从库复制主库的数据落后了几 ms。

   一般来说，如果主从延迟较为严重，有以下解决方案：

   - 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
   - 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
   - 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
   - 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

# 3. 高可用架构

## ==3.1 如何设计一个高可用系统==



## ==3.2 限流==

### 3.2.1 Redis令牌桶限流

限流组件：Guava RateLimiter，==**令牌桶算法**==

## ==3.3 熔断&降级==

Hystrix